{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(train_file, params) :\n",
    "    \n",
    "    err = subprocess.call('vw --oaa 550 --random_seed 7 -b 26 %s -k --cache_file cache.tmp %s \\\n",
    "-f kaggle_data/my_vw_model.vw' % (params, train_file) )\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predict(file_name) :\n",
    "    err = subprocess.call('vw -i kaggle_data/my_vw_model.vw -t -d %s -p kaggle_data/my_vw_pred.csv --random_seed 7' % file_name)\n",
    "\n",
    "    if err != 255 :\n",
    "        return pd.read_csv('kaggle_data/my_vw_pred.csv', header=None)\n",
    "    else :\n",
    "        print (\"prediction error\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name, user_id=True) :\n",
    "    \n",
    "    site_ids = list(['site%d'%i for i in range(1,11)])\n",
    "    # secs_names = list(['secs%d'%i for i in range(1,11)]) \n",
    "    # add_names = list(['year', 'month', 'd_week', 'hour', 'w_end', 'period', 'sess_dur', 'utc' ])\n",
    "    add_names = list(['utc', 'w_end', 'period' ])\n",
    "       \n",
    "    new_names = ['sess_len'] + site_ids + add_names\n",
    "    \n",
    "    if (user_id) :\n",
    "        new_names.append('user_id')\n",
    "    \n",
    "    # print (new_names)\n",
    "    \n",
    "    data = pd.read_csv(file_name, index_col='session_id').fillna(0)\n",
    "    N,_ = data.shape\n",
    "    \n",
    "    for j in range (1,11) :\n",
    "        data['site%d'%j] = data['site%d'%j].astype(int)\n",
    "        data['time%d'%j] = pd.to_datetime( data['time%d'%j] )\n",
    "        data['secs%d'%j] = data['time%d'%j].apply( lambda d: (d - datetime.datetime(2013,1,1)).total_seconds() ).astype(int) \n",
    "        \n",
    "    #data['month'] =  data.time1.apply ( lambda d: d.month )\n",
    "    #data['year'] =   data.time1.apply ( lambda d: d.year)\n",
    "        \n",
    "    data['hour']  =  data.time1.apply ( lambda d: d.hour )\n",
    "    data['d_week'] = data.time1.apply ( lambda d: d.dayofweek+1 )\n",
    "    data['w_end'] =  data.d_week.apply( lambda w: 1 if w==1 or w==6  else 2)\n",
    "    data['period'] = data.hour.apply  ( lambda h: 1 if h==7 else 2 if h >= 8 and h <=18 else 3  )\n",
    "    data['utc'] =    data.secs1.apply  ( lambda s: s/(60*60)).astype(int)\n",
    "    \n",
    "    # calculate durations in secs\n",
    "    ses_len = np.zeros(N, dtype=int)\n",
    "    # ses_dur = np.zeros(N, dtype=int)\n",
    "    n_sids = 1\n",
    "    for i in range(N) : #!!!!!!!!!!!!!!!!!!!!!! N\n",
    "        n_sids = 10\n",
    "        # start_time = data.loc[i+1,'secs1']\n",
    "        # end_time = data.loc[i+1,'secs10']\n",
    "        for j in range (0,20,2) :\n",
    "            if data.iloc[i,j] == 0 :\n",
    "                n_sids = int(j/2)\n",
    "                # end_time = data.loc[i+1, 'secs%d'%(n_sids)]\n",
    "                break\n",
    "        ses_len[i] = n_sids\n",
    "        \n",
    "        # duration = end_time - start_time\n",
    "        # if (duration > 0) :\n",
    "        #    ses_dur[i] = duration\n",
    "        # else :\n",
    "        #    ses_dur[i] = 1\n",
    "         \n",
    "    data['sess_len'] = ses_len.astype(int)\n",
    "    # data['sess_dur'] = ses_dur.astype(int)\n",
    "    \n",
    "    return data[new_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_vm_file_3(x, y, out_file):\n",
    "    \n",
    "    vm_file = open(out_file, 'w')\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    num_lines = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        if y is not None:\n",
    "            out_line = str(y[i])\n",
    "        else:\n",
    "            out_line = str(1)\n",
    "            \n",
    "        session_list = list()\n",
    "        n_sids = x.iloc[i, 0]\n",
    "        \n",
    "        for j in range(n_sids) :\n",
    "            session_list.append( str(x.iloc[i, j+1]) ) #  + ':' + str(x.iloc[i, 11+j]) )\n",
    "       \n",
    "        pos = 11   \n",
    "        out_line = out_line +' | ' + ' '.join(session_list)\n",
    "        out_line = out_line +' | ' + str(x.iloc[i, pos+0]) # utc\n",
    "        out_line = out_line +' | ' + str(x.iloc[i, pos+1]) # w_end\n",
    "        out_line = out_line +' | ' + str(x.iloc[i, pos+2]) # period\n",
    "        \n",
    "        #out_line = out_line +' | ' + str(x.iloc[i, pos+3]) # w_end\n",
    "        #out_line = out_line +' | ' + str(x.iloc[i, pos+4]) # period\n",
    "        #out_line = out_line +' | ' + str(x.iloc[i, pos+5]) # duration in secs\n",
    "        #out_line = out_line +' | ' + str(x.iloc[i, pos+6]) # utc in hours\n",
    "        \n",
    "        out_line = out_line + '\\n'\n",
    "        \n",
    "        # print (out_line)\n",
    "\n",
    "        vm_file.write(out_line)\n",
    "        num_lines += 1\n",
    "    \n",
    "    # print (N, num_lines)\n",
    "    vm_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_score_3(train_file, test_file, y_train, y_test, \n",
    "                params_str='--loss_function logistic -l 0.8 --decay_learning_rate 1.0' ) :  \n",
    "    \n",
    "    err = train_model(train_file, params_str)\n",
    "    \n",
    "    if (err == 255) :\n",
    "        print (\"modeling error!\")\n",
    "        return -1, -1\n",
    "\n",
    "    y_pred_train = get_predict(train_file).values.ravel()\n",
    "    \n",
    "    y_pred_test =  get_predict(test_file).values.ravel()\n",
    "    \n",
    "    return accuracy_score(y_pred_train, y_train), accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = load_data('kaggle_data/train_sessions.csv')\n",
    "train_df.to_csv('kaggle_data/train_df.csv', index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_encoder = LabelEncoder()\n",
    "train_labels = user_encoder.fit_transform(train_df['user_id']) + 1\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df, train_labels, \n",
    "                                                      test_size=0.3, random_state=7, stratify=train_labels)\n",
    "\n",
    "prepare_vm_file_3(X_train, y_train, 'kaggle_data/my_train.vw')\n",
    "prepare_vm_file_3(X_valid, y_valid, 'kaggle_data/my_valid.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic train score: 0.8071  test score: 0.5469\n",
      "squared train score: 0.7814  test score: 0.5339\n",
      "hinge train score: 0.7634  test score: 0.5248\n",
      "quantile train score: 0.7634  test score: 0.5248\n",
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "func_list = ['logistic', 'squared', 'hinge', 'quantile']\n",
    "\n",
    "for func in func_list :\n",
    "    t0, t1 = check_score_3('kaggle_data/my_train.vw', 'kaggle_data/my_valid.vw', \n",
    "                           y_train, y_valid,\n",
    "                           params_str='--passes 20 --loss_function ' + func + ' -l 0.8 --decay_learning_rate 1.0'\n",
    "                          )\n",
    "    print('%s train score: %.4f  test score: %.4f' % (func, t0, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 train score: 0.7854  test score: 0.5433\n",
      "0.7 train score: 0.8028  test score: 0.5467\n",
      "0.75 train score: 0.8053  test score: 0.5473\n",
      "Wall time: 20min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l_rate = ['0.65', '0.7', '0.75']\n",
    "\n",
    "for func in l_rate :\n",
    "    t0, t1 = check_score_3('kaggle_data/my_train.vw', 'kaggle_data/my_valid.vw', \n",
    "                           y_train, y_valid,\n",
    "                           params_str='--passes 20 --loss_function logistic  -l ' + func + ' --decay_learning_rate 1.0'\n",
    "                          )\n",
    "    print('%s train score: %.4f  test score: %.4f' % (func, t0, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85 train score: 0.8088  test score: 0.5469\n",
      "0.9 train score: 0.8007  test score: 0.5458\n",
      "0.95 train score: 0.7999  test score: 0.5450\n",
      "Wall time: 19min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l_rate = ['0.85', '0.9', '0.95']\n",
    "\n",
    "for func in l_rate :\n",
    "    t0, t1 = check_score_3('kaggle_data/my_train.vw', 'kaggle_data/my_valid.vw', \n",
    "                           y_train, y_valid,\n",
    "                           params_str='--passes 20 --loss_function logistic  -l ' + func + ' --decay_learning_rate 1.0'\n",
    "                          )\n",
    "    print('%s train score: %.4f  test score: %.4f' % (func, t0, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 train score: 0.7824  test score: 0.5413\n",
      "15 train score: 0.7962  test score: 0.5451\n",
      "25 train score: 0.8108  test score: 0.5468\n",
      "Wall time: 19min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l_passes = ['10', '15', '25']\n",
    "\n",
    "for func in l_passes :\n",
    "    t0, t1 = check_score_3('kaggle_data/my_train.vw', 'kaggle_data/my_valid.vw', \n",
    "                           y_train, y_valid,\n",
    "                           params_str='--loss_function logistic  -l 0.75 --passes ' + func + ' --decay_learning_rate 1.0'\n",
    "                          )\n",
    "    print('%s train score: %.4f  test score: %.4f' % (func, t0, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = load_data('kaggle_data/test_sessions.csv', user_id=False)\n",
    "test_df.to_csv('kaggle_data/test_df.csv', index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_submission_3(params_str) :\n",
    "        \n",
    "    train_data = pd.read_csv('kaggle_data/train_df.csv', index_col='session_id')\n",
    "    test_data = pd.read_csv('kaggle_data/test_df.csv', index_col='session_id')\n",
    "    \n",
    "    print (\".csv loaded -> \", end=\" \")\n",
    "    \n",
    "    user_encoder = LabelEncoder()\n",
    "    train_labels = user_encoder.fit_transform(train_data['user_id']) + 1\n",
    "    \n",
    "    prepare_vm_file_3(train_data, train_labels, 'kaggle_data/my_full_train.vw')\n",
    "    \n",
    "    prepare_vm_file_3(test_data, None, 'kaggle_data/my_full_test.vw')\n",
    "    \n",
    "    print (\".vw prepared -> \", end=\" \")\n",
    "    \n",
    "    err = train_model('kaggle_data/my_full_train.vw', params_str)\n",
    "    \n",
    "    if (err == 255) :\n",
    "        print (\"modeling error!\")\n",
    "        return\n",
    "    else :\n",
    "        print (\"model trained -> \", end=\" \")\n",
    "    \n",
    "    y_pred = get_predict('kaggle_data/my_full_test.vw')\n",
    "    \n",
    "    print (\"predict done -> \", end=\" \")\n",
    "    \n",
    "    y_subm = user_encoder.inverse_transform( y_pred - 1 )\n",
    "    \n",
    "    write_to_submission_file(y_subm, 'kaggle_data/sokolov_submission.csv')\n",
    "    \n",
    "    print (\"result file: kaggle_data/sokolov_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv loaded ->  .vw prepared ->  model trained ->  predict done ->  result file: kaggle_data/sokolov_submission.csv\n",
      "Wall time: 14min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prep_submission_3( '--loss_function logistic --passes 25 -l 0.75 --decay_learning_rate 1.0' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
